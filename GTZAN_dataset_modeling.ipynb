{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1032238,
          "sourceType": "datasetVersion",
          "datasetId": 568973
        }
      ],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Modeling the GTZAN Dataset for Music Genre Classification"
      ],
      "metadata": {
        "id": "VNb7tsM4xVWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GTZAN dataset is a widely used collection of audio files used for music genre classification research. It consists of 1,000 audio tracks each 30 seconds long, sampled at 22,050 Hz and stored in the uncompressed WAV format. The dataset covers 10 genres, with 100 tracks per genre. The genres included are blues, classical, country, disco, hip-hop, jazz, metal, pop, reggae, and rock."
      ],
      "metadata": {
        "id": "315XzPPaxWmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "Sxk3zqXxx454"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:17:12.655852Z",
          "iopub.execute_input": "2024-03-23T07:17:12.656678Z",
          "iopub.status.idle": "2024-03-23T07:17:12.662047Z",
          "shell.execute_reply.started": "2024-03-23T07:17:12.656648Z",
          "shell.execute_reply": "2024-03-23T07:17:12.661095Z"
        },
        "trusted": true,
        "id": "aq1r89V1wqSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The load_and_preprocess_image function loads an image from a given path, resizes it to a standard size (224x224 pixels), converts it to a numpy array, and then normalizes the pixel values to be between 0 and 1. This is essential for ensuring that the image data is in a suitable format for feeding into a neural network.\n",
        "\n",
        "The load_and_preprocess_audio function loads an audio file from a given path, ensures it has the desired length (in samples), and then computes the Mel-frequency cepstral coefficients (MFCCs) from the audio data. MFCCs are a representation of the short-term power spectrum of sound, often used as features for audio processing tasks like speech recognition or music genre classification."
      ],
      "metadata": {
        "id": "kxhd2IAOy_Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    \"\"\"\n",
        "    Load and preprocess an image from the given path.\n",
        "\n",
        "    Args:\n",
        "    - image_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "    - img_array (numpy.ndarray): Preprocessed image array.\n",
        "    \"\"\"\n",
        "    # Load the image and resize it to (224, 224) as required by some models\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = image.img_to_array(img)\n",
        "    # Normalize the image array to values between 0 and 1\n",
        "    return img_array/255.0\n",
        "\n",
        "def load_and_preprocess_audio(audio_path, max_audio_length):\n",
        "    \"\"\"\n",
        "    Load and preprocess an audio file from the given path.\n",
        "\n",
        "    Args:\n",
        "    - audio_path (str): Path to the audio file.\n",
        "    - max_audio_length (int): Maximum length of audio data (in samples).\n",
        "\n",
        "    Returns:\n",
        "    - mfccs (numpy.ndarray): Mel-frequency cepstral coefficients (MFCCs) of the audio.\n",
        "    \"\"\"\n",
        "    # Load the audio data\n",
        "    audio_data, _ = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
        "\n",
        "    # Ensure the audio has the desired length\n",
        "    if len(audio_data) < max_audio_length:\n",
        "        # If too short, pad with zeros\n",
        "        audio_data = np.pad(audio_data, (0, max_audio_length - len(audio_data)))\n",
        "    else:\n",
        "        # If too long, truncate\n",
        "        audio_data = audio_data[:max_audio_length]\n",
        "\n",
        "    # Compute MFCCs (Mel-frequency cepstral coefficients) from the audio data\n",
        "    mfccs = librosa.feature.mfcc(y=audio_data, sr=SAMPLE_RATE, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "    return mfccs\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:17:12.665039Z",
          "iopub.execute_input": "2024-03-23T07:17:12.665353Z",
          "iopub.status.idle": "2024-03-23T07:17:12.685873Z",
          "shell.execute_reply.started": "2024-03-23T07:17:12.665319Z",
          "shell.execute_reply": "2024-03-23T07:17:12.685102Z"
        },
        "trusted": true,
        "id": "eDtnpkNzwqSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.util\n",
        "\n",
        "# Constants\n",
        "SAMPLE_RATE = 22050  # Sample rate of the audio\n",
        "TRACK_DURATION = 30  # Duration of each audio track in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION  # Total samples in each track\n",
        "\n",
        "num_mfcc = 13  # Number of MFCC coefficients to extract\n",
        "n_fft = 2048  # Length of the FFT window\n",
        "hop_length = 512  # Hop length for the STFT\n",
        "\n",
        "num_segments = 15  # Number of segments to divide each audio track into\n",
        "\n",
        "# Calculate the maximum audio length in samples based on the number of segments\n",
        "max_audio_length = SAMPLES_PER_TRACK * num_segments  # Max samples for all segments\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:17:12.687490Z",
          "iopub.execute_input": "2024-03-23T07:17:12.687927Z",
          "iopub.status.idle": "2024-03-23T07:17:12.695684Z",
          "shell.execute_reply.started": "2024-03-23T07:17:12.687895Z",
          "shell.execute_reply": "2024-03-23T07:17:12.694937Z"
        },
        "trusted": true,
        "id": "0ttU3kW-wqSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "\n",
        "# Function to create combinations of image and audio data\n",
        "def create_data_combinations(image_folder, audio_folder, max_audio_length):\n",
        "    # Initialize empty lists to store images, labels, and audio data\n",
        "    images, labels, voices = [], [], []\n",
        "\n",
        "    # Mapping of class names to numeric labels\n",
        "    class_mapping = {\n",
        "        'disco': 0,\n",
        "        'metal': 1,\n",
        "        'reggae': 2,\n",
        "        'blues': 3,\n",
        "        'rock': 4,\n",
        "        'classical': 5,\n",
        "        'jazz': 6,\n",
        "        'hiphop': 7,\n",
        "        'country': 8,\n",
        "        'pop': 9\n",
        "    }\n",
        "\n",
        "    # Iterate through each class folder in the image folder\n",
        "    for class_folder in os.listdir(image_folder):\n",
        "        # Path to the current class folder\n",
        "        class_path = os.path.join(image_folder, class_folder)\n",
        "        i = 0\n",
        "        # Iterate through each image in the class folder\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)# Path to the image file\n",
        "            # Path to the audio folder corresponding to the class\n",
        "            audio_path = os.path.join(audio_folder, class_folder)\n",
        "            # Load and preprocess image data\n",
        "            img_data = load_and_preprocess_image(image_path)\n",
        "            # Get a list of audio files in the audio folder\n",
        "            audio_files = os.listdir(audio_path)\n",
        "            # Select a random sample of audio files (1 or less)\n",
        "            selected_audio_files = random.sample(audio_files, min(1, len(audio_files)))\n",
        "            # Iterate through selected audio files\n",
        "            for audio in selected_audio_files:\n",
        "                try:\n",
        "                    # Path to the audio file\n",
        "                    data_path = os.path.join(audio_path, audio)\n",
        "                    # Load and preprocess audio data\n",
        "                    audio_data = load_and_preprocess_audio(data_path, max_audio_length)\n",
        "                    # Append image, audio, and label to the respective lists\n",
        "                    images.append(img_data)\n",
        "                    voices.append(audio_data)\n",
        "                    label = class_mapping[class_folder]\n",
        "                    labels.append(label)\n",
        "                except:\n",
        "                    continue\n",
        "            # Limit the number of images per class to 30\n",
        "            if i == 30:\n",
        "                break\n",
        "            i += 1\n",
        "        # Print the class name after processing images for that class\n",
        "        print(class_folder)\n",
        "\n",
        "    return images, voices, labels\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:17:12.696989Z",
          "iopub.execute_input": "2024-03-23T07:17:12.697505Z",
          "iopub.status.idle": "2024-03-23T07:17:12.709460Z",
          "shell.execute_reply.started": "2024-03-23T07:17:12.697475Z",
          "shell.execute_reply": "2024-03-23T07:17:12.708670Z"
        },
        "trusted": true,
        "id": "9ADUTqhCwqSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Change the current working directory to the specified path\n",
        "os.chdir(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data\")\n",
        "\n",
        "# Create data combinations from image and audio folders\n",
        "image_folder = 'images_original'\n",
        "audio_folder = 'genres_original'\n",
        "# Call the create_data_combinations function to generate image, audio, and label combinations\n",
        "images, voices, labels = create_data_combinations(image_folder, audio_folder, max_audio_length)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:17:12.711548Z",
          "iopub.execute_input": "2024-03-23T07:17:12.711887Z",
          "iopub.status.idle": "2024-03-23T07:20:15.382987Z",
          "shell.execute_reply.started": "2024-03-23T07:17:12.711859Z",
          "shell.execute_reply": "2024-03-23T07:20:15.381514Z"
        },
        "trusted": true,
        "id": "cl5Q65UjwqSe",
        "outputId": "94b216e1-b13f-462f-d293-0402149c91ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "disco\nmetal\nreggae\nblues\nrock\nclassical\njazz\nhiphop\ncountry\npop\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features and labels\n",
        "X_image = np.array(images)\n",
        "X_audio = np.array(voices)\n",
        "Y_labels = np.array(labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.388674Z",
          "iopub.execute_input": "2024-03-23T07:20:15.392679Z",
          "iopub.status.idle": "2024-03-23T07:20:15.531295Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.392622Z",
          "shell.execute_reply": "2024-03-23T07:20:15.530256Z"
        },
        "trusted": true,
        "id": "50gTTRnhwqSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_audio.shape,X_image.shape,Y_labels.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.532423Z",
          "iopub.execute_input": "2024-03-23T07:20:15.532735Z",
          "iopub.status.idle": "2024-03-23T07:20:15.539084Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.532711Z",
          "shell.execute_reply": "2024-03-23T07:20:15.538193Z"
        },
        "trusted": true,
        "id": "OR30TYxKwqSh",
        "outputId": "5bc7d80b-0385-41b6-d303-a5f11e93e6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((310, 13, 19380), (310, 224, 224, 3), (310,))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(Y_labels))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.542047Z",
          "iopub.execute_input": "2024-03-23T07:20:15.542341Z",
          "iopub.status.idle": "2024-03-23T07:20:15.548233Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.542318Z",
          "shell.execute_reply": "2024-03-23T07:20:15.547302Z"
        },
        "trusted": true,
        "id": "ydpYNiI6wqSi",
        "outputId": "9e4a2a44-9028-4d58-a811-5fba69a9477f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[0 1 2 3 4 5 6 7 8 9]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the integer labels to categorical labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "Y_labels = to_categorical(Y_labels, num_classes=10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.549356Z",
          "iopub.execute_input": "2024-03-23T07:20:15.549699Z",
          "iopub.status.idle": "2024-03-23T07:20:15.556818Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.549669Z",
          "shell.execute_reply": "2024-03-23T07:20:15.555983Z"
        },
        "trusted": true,
        "id": "ZFkg0TYQwqSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_image_train, X_image_val, X_audio_train, X_audio_val, y_train, y_val = train_test_split(\n",
        "    X_image, X_audio, Y_labels, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.557715Z",
          "iopub.execute_input": "2024-03-23T07:20:15.558004Z",
          "iopub.status.idle": "2024-03-23T07:20:15.675080Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.557981Z",
          "shell.execute_reply": "2024-03-23T07:20:15.674284Z"
        },
        "trusted": true,
        "id": "uNzJcoqNwqSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_image_train.shape,X_audio_train.shape,y_train.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.676329Z",
          "iopub.execute_input": "2024-03-23T07:20:15.676654Z",
          "iopub.status.idle": "2024-03-23T07:20:15.683163Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.676628Z",
          "shell.execute_reply": "2024-03-23T07:20:15.682022Z"
        },
        "trusted": true,
        "id": "-c2Jzk00wqSl",
        "outputId": "2d84418b-5a5f-4f6d-cf78-308c1eef22b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((248, 224, 224, 3), (248, 13, 19380), (248, 10))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_image_val.shape,X_audio_val.shape,y_val.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.684457Z",
          "iopub.execute_input": "2024-03-23T07:20:15.684853Z",
          "iopub.status.idle": "2024-03-23T07:20:15.694060Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.684821Z",
          "shell.execute_reply": "2024-03-23T07:20:15.693010Z"
        },
        "trusted": true,
        "id": "rbUw9WlywqSn",
        "outputId": "c1fc6245-f3bc-4f09-eed4-be20f5f261d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((62, 224, 224, 3), (62, 13, 19380), (62, 10))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, LSTM, concatenate\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Load pre-trained VGG16 model with weights trained on ImageNet\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of VGG16\n",
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.695174Z",
          "iopub.execute_input": "2024-03-23T07:20:15.695429Z",
          "iopub.status.idle": "2024-03-23T07:20:15.958399Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.695408Z",
          "shell.execute_reply": "2024-03-23T07:20:15.957417Z"
        },
        "trusted": true,
        "id": "cgmNi-hpwqSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the shape of the input data\n",
        "audio_input_shape = (num_mfcc, X_audio.shape[2])  # (number of MFCC coefficients, audio length)\n",
        "image_input_shape = X_image.shape[1:]  # (image height, image width, number of channels)\n",
        "\n",
        "# Define the input layers\n",
        "audio_input = Input(shape=audio_input_shape, name='audio_input')\n",
        "image_input = Input(shape=image_input_shape, name='image_input')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.959632Z",
          "iopub.execute_input": "2024-03-23T07:20:15.959989Z",
          "iopub.status.idle": "2024-03-23T07:20:15.968807Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.959958Z",
          "shell.execute_reply": "2024-03-23T07:20:15.967828Z"
        },
        "trusted": true,
        "id": "8uYMjiR6wqSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio processing\n",
        "audio_lstm = LSTM(64)(audio_input)\n",
        "audio_output = Dense(32, activation='relu')(audio_lstm)\n",
        "\n",
        "# Image processing using VGG16\n",
        "image_vgg = vgg_model(image_input)\n",
        "image_flatten = Flatten()(image_vgg)\n",
        "image_output = Dense(512, activation='relu')(image_flatten)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:15.970256Z",
          "iopub.execute_input": "2024-03-23T07:20:15.970572Z",
          "iopub.status.idle": "2024-03-23T07:20:16.010572Z",
          "shell.execute_reply.started": "2024-03-23T07:20:15.970543Z",
          "shell.execute_reply": "2024-03-23T07:20:16.009804Z"
        },
        "trusted": true,
        "id": "7vrGBOPXwqSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the outputs of audio and image processing\n",
        "merged = concatenate([audio_output, image_output])\n",
        "merged = Dense(512, activation='relu')(merged)\n",
        "\n",
        "# Final output layer\n",
        "output = Dense(10, activation='softmax')(merged)  # Assuming a binary classification task\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=[image_input, audio_input], outputs=output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:16.014268Z",
          "iopub.execute_input": "2024-03-23T07:20:16.014582Z",
          "iopub.status.idle": "2024-03-23T07:20:16.039034Z",
          "shell.execute_reply.started": "2024-03-23T07:20:16.014560Z",
          "shell.execute_reply": "2024-03-23T07:20:16.038340Z"
        },
        "trusted": true,
        "id": "kNbrBaBywqSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:16.039992Z",
          "iopub.execute_input": "2024-03-23T07:20:16.040243Z",
          "iopub.status.idle": "2024-03-23T07:20:16.069348Z",
          "shell.execute_reply.started": "2024-03-23T07:20:16.040222Z",
          "shell.execute_reply": "2024-03-23T07:20:16.068508Z"
        },
        "trusted": true,
        "id": "8z9-v9U7wqSq",
        "outputId": "4b4de191-17bb-4a30-d7af-7bd107e696be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"functional_3\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ image_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ audio_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m19380\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │ \u001b[38;5;34m14,714,688\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │  \u001b[38;5;34m4,977,920\u001b[0m │ audio_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ vgg16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │ \u001b[38;5;34m12,845,568\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m544\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m279,040\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m5,130\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ image_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ audio_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19380</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,977,920</span> │ audio_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ vgg16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,568</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">279,040</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,824,426\u001b[0m (125.22 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,824,426</span> (125.22 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,109,738\u001b[0m (69.08 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,109,738</span> (69.08 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n</pre>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    [X_image_train, X_audio_train],\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    validation_data=([X_image_val, X_audio_val], y_val),\n",
        "    batch_size=2\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:22:12.769615Z",
          "iopub.execute_input": "2024-03-23T07:22:12.770738Z",
          "iopub.status.idle": "2024-03-23T07:26:24.983351Z",
          "shell.execute_reply.started": "2024-03-23T07:22:12.770698Z",
          "shell.execute_reply": "2024-03-23T07:26:24.982506Z"
        },
        "trusted": true,
        "id": "-HP_rZNLwqSr",
        "outputId": "bc61ac5a-3e95-4176-ccff-3d68dc845b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7190 - loss: 0.7594 - val_accuracy: 0.4032 - val_loss: 1.8729\nEpoch 2/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8363 - loss: 0.5748 - val_accuracy: 0.4516 - val_loss: 2.0532\nEpoch 3/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8400 - loss: 0.5215 - val_accuracy: 0.4516 - val_loss: 2.0941\nEpoch 4/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8830 - loss: 0.3686 - val_accuracy: 0.4677 - val_loss: 2.1275\nEpoch 5/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9247 - loss: 0.3018 - val_accuracy: 0.3548 - val_loss: 2.4990\nEpoch 6/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8880 - loss: 0.3479 - val_accuracy: 0.5000 - val_loss: 1.9349\nEpoch 7/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9396 - loss: 0.2239 - val_accuracy: 0.4355 - val_loss: 2.6410\nEpoch 8/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8956 - loss: 0.3561 - val_accuracy: 0.4032 - val_loss: 2.8591\nEpoch 9/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9076 - loss: 0.2744 - val_accuracy: 0.4839 - val_loss: 1.9074\nEpoch 10/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9291 - loss: 0.2871 - val_accuracy: 0.4355 - val_loss: 2.2658\nEpoch 11/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9408 - loss: 0.1680 - val_accuracy: 0.3871 - val_loss: 2.6709\nEpoch 12/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8970 - loss: 0.2663 - val_accuracy: 0.4194 - val_loss: 2.7525\nEpoch 13/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9197 - loss: 0.1821 - val_accuracy: 0.4677 - val_loss: 2.6025\nEpoch 14/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9594 - loss: 0.1286 - val_accuracy: 0.4355 - val_loss: 3.0779\nEpoch 15/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8454 - loss: 0.3993 - val_accuracy: 0.3871 - val_loss: 4.4837\nEpoch 16/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8088 - loss: 0.4496 - val_accuracy: 0.4355 - val_loss: 2.7702\nEpoch 17/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9341 - loss: 0.1787 - val_accuracy: 0.4194 - val_loss: 2.9093\nEpoch 18/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9073 - loss: 0.2093 - val_accuracy: 0.4355 - val_loss: 2.8400\nEpoch 19/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9802 - loss: 0.0443 - val_accuracy: 0.4516 - val_loss: 3.2533\nEpoch 20/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9297 - loss: 0.1885 - val_accuracy: 0.4516 - val_loss: 3.2094\nEpoch 21/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9529 - loss: 0.1253 - val_accuracy: 0.3871 - val_loss: 3.5306\nEpoch 22/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9599 - loss: 0.1711 - val_accuracy: 0.5645 - val_loss: 2.5593\nEpoch 23/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9252 - loss: 0.1923 - val_accuracy: 0.4032 - val_loss: 3.4335\nEpoch 24/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9153 - loss: 0.2311 - val_accuracy: 0.4032 - val_loss: 3.1624\nEpoch 25/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9256 - loss: 0.2331 - val_accuracy: 0.4355 - val_loss: 3.2575\nEpoch 26/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9585 - loss: 0.1190 - val_accuracy: 0.4516 - val_loss: 2.7639\nEpoch 27/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9994 - loss: 0.0187 - val_accuracy: 0.4677 - val_loss: 3.2409\nEpoch 28/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9691 - loss: 0.0870 - val_accuracy: 0.3871 - val_loss: 3.1944\nEpoch 29/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9750 - loss: 0.0771 - val_accuracy: 0.4516 - val_loss: 3.0986\nEpoch 30/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9725 - loss: 0.0554 - val_accuracy: 0.4194 - val_loss: 3.5535\nEpoch 31/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9955 - loss: 0.0372 - val_accuracy: 0.4677 - val_loss: 3.4379\nEpoch 32/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.4516 - val_loss: 3.4914\nEpoch 33/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9887 - loss: 0.0233 - val_accuracy: 0.4516 - val_loss: 3.5196\nEpoch 34/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9229 - loss: 0.1917 - val_accuracy: 0.3871 - val_loss: 4.0088\nEpoch 35/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8694 - loss: 0.4812 - val_accuracy: 0.4677 - val_loss: 3.4605\nEpoch 36/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8601 - loss: 0.4497 - val_accuracy: 0.3548 - val_loss: 3.5490\nEpoch 37/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8446 - loss: 0.4738 - val_accuracy: 0.4677 - val_loss: 2.4566\nEpoch 38/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9355 - loss: 0.2091 - val_accuracy: 0.4677 - val_loss: 2.9039\nEpoch 39/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9952 - loss: 0.0390 - val_accuracy: 0.4839 - val_loss: 3.1178\nEpoch 40/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9916 - loss: 0.0391 - val_accuracy: 0.4194 - val_loss: 3.7171\nEpoch 41/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9146 - loss: 0.2741 - val_accuracy: 0.4516 - val_loss: 2.8964\nEpoch 42/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9777 - loss: 0.0778 - val_accuracy: 0.5161 - val_loss: 2.8596\nEpoch 43/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9871 - loss: 0.0784 - val_accuracy: 0.5000 - val_loss: 3.4587\nEpoch 44/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9949 - loss: 0.0166 - val_accuracy: 0.4839 - val_loss: 3.5237\nEpoch 45/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9932 - loss: 0.0250 - val_accuracy: 0.5484 - val_loss: 2.8793\nEpoch 46/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9947 - loss: 0.0089 - val_accuracy: 0.4839 - val_loss: 3.2580\nEpoch 47/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.4839 - val_loss: 3.2311\nEpoch 48/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.5161 - val_loss: 3.3110\nEpoch 49/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.5161 - val_loss: 3.3852\nEpoch 50/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.4839 - val_loss: 3.4939\nEpoch 51/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.4839 - val_loss: 3.6209\nEpoch 52/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.5161 - val_loss: 3.5350\nEpoch 53/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.4839 - val_loss: 3.5957\nEpoch 54/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.4839 - val_loss: 3.6799\nEpoch 55/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 9.3864e-04 - val_accuracy: 0.5000 - val_loss: 3.7294\nEpoch 56/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 8.9784e-04 - val_accuracy: 0.4839 - val_loss: 3.7595\nEpoch 57/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 9.8405e-04 - val_accuracy: 0.4677 - val_loss: 3.8747\nEpoch 58/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.4839 - val_loss: 3.7571\nEpoch 59/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 8.3298e-04 - val_accuracy: 0.4677 - val_loss: 3.9584\nEpoch 60/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 9.4978e-04 - val_accuracy: 0.4839 - val_loss: 3.8896\nEpoch 61/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 5.9441e-04 - val_accuracy: 0.4516 - val_loss: 3.9761\nEpoch 62/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 7.5612e-04 - val_accuracy: 0.4839 - val_loss: 3.9624\nEpoch 63/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.2721e-04 - val_accuracy: 0.4677 - val_loss: 4.0435\nEpoch 64/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 6.6065e-04 - val_accuracy: 0.4516 - val_loss: 3.9900\nEpoch 65/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.1520e-04 - val_accuracy: 0.4677 - val_loss: 4.0779\nEpoch 66/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 4.4173e-04 - val_accuracy: 0.4677 - val_loss: 4.0652\nEpoch 67/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.6597e-04 - val_accuracy: 0.4839 - val_loss: 4.1111\nEpoch 68/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.9432e-04 - val_accuracy: 0.4839 - val_loss: 4.1510\nEpoch 69/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.2090e-04 - val_accuracy: 0.4839 - val_loss: 4.1964\nEpoch 70/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.0747e-04 - val_accuracy: 0.4677 - val_loss: 4.1707\nEpoch 71/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.1079e-04 - val_accuracy: 0.4839 - val_loss: 4.2482\nEpoch 72/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.3606e-04 - val_accuracy: 0.5000 - val_loss: 4.2205\nEpoch 73/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.2811e-04 - val_accuracy: 0.5000 - val_loss: 4.2562\nEpoch 74/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.8434e-04 - val_accuracy: 0.4839 - val_loss: 4.2893\nEpoch 75/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.4329e-04 - val_accuracy: 0.4839 - val_loss: 4.3222\nEpoch 76/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.6447e-04 - val_accuracy: 0.5000 - val_loss: 4.2745\nEpoch 77/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.5895e-04 - val_accuracy: 0.4677 - val_loss: 4.3121\nEpoch 78/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.8460e-04 - val_accuracy: 0.4839 - val_loss: 4.3080\nEpoch 79/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.5448e-04 - val_accuracy: 0.4516 - val_loss: 4.3964\nEpoch 80/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.9556e-04 - val_accuracy: 0.5000 - val_loss: 4.4414\nEpoch 81/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.7169e-04 - val_accuracy: 0.4677 - val_loss: 4.4695\nEpoch 82/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.4516e-04 - val_accuracy: 0.4839 - val_loss: 4.5066\nEpoch 83/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.4552e-04 - val_accuracy: 0.4839 - val_loss: 4.5151\nEpoch 84/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.0273e-04 - val_accuracy: 0.4677 - val_loss: 4.5556\nEpoch 85/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.0804e-04 - val_accuracy: 0.4677 - val_loss: 4.5984\nEpoch 86/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.0458e-04 - val_accuracy: 0.4677 - val_loss: 4.6157\nEpoch 87/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.0616e-04 - val_accuracy: 0.4677 - val_loss: 4.5939\nEpoch 88/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.0174e-04 - val_accuracy: 0.4839 - val_loss: 4.5669\nEpoch 89/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 8.5375e-05 - val_accuracy: 0.5000 - val_loss: 4.6330\nEpoch 90/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 9.2105e-05 - val_accuracy: 0.4839 - val_loss: 4.6086\nEpoch 91/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 8.2496e-05 - val_accuracy: 0.4839 - val_loss: 4.6551\nEpoch 92/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 6.9337e-05 - val_accuracy: 0.4677 - val_loss: 4.7987\nEpoch 93/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 7.6518e-05 - val_accuracy: 0.5000 - val_loss: 4.6844\nEpoch 94/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 6.7547e-05 - val_accuracy: 0.4839 - val_loss: 4.7626\nEpoch 95/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 5.6295e-05 - val_accuracy: 0.4677 - val_loss: 4.8237\nEpoch 96/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.6478e-05 - val_accuracy: 0.5000 - val_loss: 4.7415\nEpoch 97/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 6.2316e-05 - val_accuracy: 0.4516 - val_loss: 4.8622\nEpoch 98/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.6891e-05 - val_accuracy: 0.4677 - val_loss: 4.8542\nEpoch 99/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.2853e-05 - val_accuracy: 0.4677 - val_loss: 4.8720\nEpoch 100/100\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.7536e-05 - val_accuracy: 0.4677 - val_loss: 4.9428\n",
          "output_type": "stream"
        },
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x7dff4b7d2b30>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate([X_image_val, X_audio_val], y_val)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:26:24.984955Z",
          "iopub.execute_input": "2024-03-23T07:26:24.985230Z",
          "iopub.status.idle": "2024-03-23T07:26:25.324433Z",
          "shell.execute_reply.started": "2024-03-23T07:26:24.985207Z",
          "shell.execute_reply": "2024-03-23T07:26:25.323456Z"
        },
        "trusted": true,
        "id": "2hrzJMmLwqSr",
        "outputId": "0ecb1d06-dc1c-4070-f256-943be0b2f4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4264 - loss: 5.5020\nTest accuracy: 0.4677419364452362\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping of class names to numeric labels\n",
        "class_mapping = {\n",
        "    'disco': 0,\n",
        "    'metal': 1,\n",
        "    'reggae': 2,\n",
        "    'blues': 3,\n",
        "    'rock': 4,\n",
        "    'classical': 5,\n",
        "    'jazz': 6,\n",
        "    'hiphop': 7,\n",
        "    'country': 8,\n",
        "    'pop': 9\n",
        "    }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:26:25.325672Z",
          "iopub.execute_input": "2024-03-23T07:26:25.326322Z",
          "iopub.status.idle": "2024-03-23T07:26:25.331288Z",
          "shell.execute_reply.started": "2024-03-23T07:26:25.326286Z",
          "shell.execute_reply": "2024-03-23T07:26:25.330361Z"
        },
        "trusted": true,
        "id": "JxsSWWztwqSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the paths to the new audio and image files\n",
        "new_audio_path = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/blues/blues.00000.wav'\n",
        "new_image_path = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/images_original/blues/blues00000.png'\n",
        "\n",
        "# Load and preprocess the single image and audio data\n",
        "new_img_data = load_and_preprocess_image(new_image_path)\n",
        "new_audio_data = load_and_preprocess_audio(new_audio_path, max_audio_length)\n",
        "\n",
        "# Reshape the data to match the model input shape\n",
        "new_img_data = np.expand_dims(new_img_data, axis=0)\n",
        "new_audio_data = np.expand_dims(new_audio_data, axis=0)\n",
        "\n",
        "# Make a prediction using the model\n",
        "prediction = model.predict([new_img_data, new_audio_data])\n",
        "# Get the predicted label\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "print(f'The predicted label is: {predicted_label}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:26:25.333521Z",
          "iopub.execute_input": "2024-03-23T07:26:25.333922Z",
          "iopub.status.idle": "2024-03-23T07:26:25.890627Z",
          "shell.execute_reply.started": "2024-03-23T07:26:25.333892Z",
          "shell.execute_reply": "2024-03-23T07:26:25.889734Z"
        },
        "trusted": true,
        "id": "dNvRRICdwqSt",
        "outputId": "9f292ff6-69c6-4ec8-fe10-67f7e1d10fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nThe predicted label is: 3\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# Assuming you have trained your model and obtained predictions on the validation set\n",
        "predictions = model.predict([X_image_val, X_audio_val])\n",
        "\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "actual_labels = np.argmax(y_val, axis=1)\n",
        "# Create a list of class labels\n",
        "class_labels = list(class_mapping.keys())\n",
        "print()\n",
        "# Generate confusion matrix with class names\n",
        "conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Generate classification report with class names\n",
        "class_report = classification_report(actual_labels, predicted_labels, target_names=class_labels)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T07:20:45.777412Z",
          "iopub.execute_input": "2024-03-23T07:20:45.777945Z",
          "iopub.status.idle": "2024-03-23T07:20:46.671341Z",
          "shell.execute_reply.started": "2024-03-23T07:20:45.777906Z",
          "shell.execute_reply": "2024-03-23T07:20:46.670274Z"
        },
        "trusted": true,
        "id": "0eO0F9DVwqSu",
        "outputId": "64c4e70c-ac71-4e14-fc22-1b1937db30b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n\nConfusion Matrix:\n[[0 0 1 5 0 0 0 1 0 0]\n [0 0 0 2 0 0 0 4 0 0]\n [0 2 3 1 0 0 1 1 0 0]\n [0 0 0 5 1 0 1 0 0 0]\n [0 2 0 0 0 0 0 0 0 0]\n [0 0 0 0 1 3 4 0 1 0]\n [0 0 1 2 0 0 2 0 1 0]\n [0 1 0 0 0 0 0 4 0 1]\n [0 0 0 0 0 1 2 0 0 0]\n [0 0 2 0 0 0 0 4 0 2]]\nClassification Report:\n              precision    recall  f1-score   support\n\n       disco       0.00      0.00      0.00         7\n       metal       0.00      0.00      0.00         6\n      reggae       0.43      0.38      0.40         8\n       blues       0.33      0.71      0.45         7\n        rock       0.00      0.00      0.00         2\n   classical       0.75      0.33      0.46         9\n        jazz       0.20      0.33      0.25         6\n      hiphop       0.29      0.67      0.40         6\n     country       0.00      0.00      0.00         3\n         pop       0.67      0.25      0.36         8\n\n    accuracy                           0.31        62\n   macro avg       0.27      0.27      0.23        62\nweighted avg       0.33      0.31      0.28        62\n\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The model achieves an accuracy of 32% on the validation set->with 10 epochs\n",
        "# model performs reasonably well for some classes, such as 'disco' and 'metal', it struggles with others, such as 'country'."
      ],
      "metadata": {
        "id": "uUBmNnoAwqSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nWgtesAwqSw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}